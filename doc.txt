Yup, that's right. There's a sparse voxel octree behind it all, so you get to see the larger levels of the tree as you pass through them. When this video was taken I began the traversal from the node containing the entire world rather than a leaf node (which I have O(1) access to). I later found that starting traversal from a leaf was faster when you're close to the ground and faster from the root when you're either outside the world or at least far enough from it that you traverse larger voxels for a while before drilling down towards the leaves.

Indeed the start-to-end time of a pixel is not necessarily a good measure of very much given the parallelism and latency hiding inherent to a GPU, as you suggest. The amount of memory used by a world this is actually rather less than you might expect. This particular level is 1600 x 214 x 1424. The current storage requirement is actually very reasonable at only 5 bits per block (297MB). I store two textures, one stores the block ID (8 bits) in a 1600 x 1424 2D-array texture with 214 slices (~470MB). The second texture is a 1024 x 128 x 1024 3D texture with full mip chain to store the octree (~150MB), this one has to be rounded up to the first power of two greater than half the world dimensions. Each texel is 8 bits and indicates the presence of blocks in the 8 children in the tree. I then take advantage of Tiled Resources to decommit any memory pages that are entirely '0' (air), this forms around 50% of both textures, reducing the memory footprint to around 5 bits per block instead of ~9.2 (8 + 1.1666. 1.1666 as a 3D mip chain is 1/6th the size of the base).

One advantage of being able to decommit 'empty' areas of both textures would be to extend the maximum height of the world beyond 256 blocks up to the maximum size supported by the hardware for a 2D-array texture's third dimension (currently 2048) for almost zero extra memory, assuming blocks above the ~200 mark were few and far between as they are today.

I'm certainly interested by what using the CPU could add to the equation. I'd be curious to see what sort of performance could be coaxed out of the same algorithm running on a high-end CPU. Currently the CPUs sit idle while the GPU does all the work, but I've been thinking about what they might be best suited to try and do. Perhaps some sort of coarse screen-space rasterization of the world to provide the GPU with a conservative first potential point of intersection with the world. This could perhaps reduce the number of iterations per pixel to numbers quite a bit lower than I see right now. The world is already treated as a hierarchy of voxels, I definitely think there's mileage in now treating the screen as a hierarchy (a quad-tree of sorts) as there's a lot of coherence between pixels in their eventual intersection with the world and thus a lot of work that could be shared across tiles/groups of neighbouring pixels.

My day job certainly ticks the right boxes and helps scratch the CPU/GPU optimisation itch! Feel free to follow me on twitter (@adamjmiles) if that's your thing.ï»¿